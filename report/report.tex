\documentclass[12pt]{extarticle}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{fancyvrb}
\usepackage{minted}
\usepackage{enumitem}
\usepackage[margin=1.2in]{geometry}
\VerbatimFootnotes

\interfootnotelinepenalty=10000

\title{Rescaling of Timely Dataflow}
\author{Lorenzo Selvatici}
\date{Aug 2019}

\begin{document}

\maketitle

\section{Introduction}

This document summarizes the work done to support dynamic rescaling of timely dataflow\footnote{https://github.com/LorenzSelv/timely-dataflow/tree/rescaling-p2p}.

In a nutshell, timely runs distributed dataflow computation in a cluster. The shape of the cluster is fixed
when first initializing the computation: how many timely processes (likely spread across several machines) and how many worker threads per timely process.
With this project, we allow the addition of new worker processes to the cluster.

In long running jobs with unpredictable workloads, it is likely that the initial configuration will not be the ideal one.
As such, there is the need to scale-out by adding more workers (and scale-in, by removing worker processes).

\section{Timely Model}

* each worker has a copy of the entire dataflow
* async
* progress tracking

\section{Rescaling the computation}

We now go into details of how the rescaling is actually implemented.
Firstly, a high-level overview of the key points that need to be dealt with is given.
Secondly, we present the design options for the initialization of the progress tracking state for the new worker.
Lastly, we describe the (rather smooth) integration with Megaphone.

\subsection{Communication Infrastructure}

Rescaling the computation is possible only when running in cluster mode: multiple timely processes, each wrapping several worker
threads, are established connections to each other and exchange both data and progress updates.

In this setting, "adding more workers" means adding another timely process with the same number of worker threads
of every other timely process in the cluster.

Communication among workers happens in two instances:
\begin{itemize}
    \item \verb|exchange| operator
    \item progress updates broadcast
\end{itemize}

In both cases, communication is enabled by \textit{allocating a channel} which contains an endpoint to every other worker
for both sending and receiving (\verb|Pusher| and \verb|Puller| traits, respectively).

Channel allocations happen while building the dataflow within the \verb|worker::dataflow| function call.

If a new worker process joins the cluster, we need to \textit{back-fill} these previously allocated channels.
We do this by storing a closure for each past allocation, so that when the new worker initiates the connection
we can invoke these closures which add the supplied pushers to the list of pushers forming the channel.

Each channel is associated with a specific data type.
Thus, we cannot simply store a map of \verb|(channel id => channel handle|, as collections can be generic but also need to be homogeneous.
One might work around this by using trait objects, but then the channel would be associated with the trait object itself rather than the concrete
type.

Moreover, fast-forwarding a bit, having a closure turned out to be very handy when implementing the bootstrap protocol to initialize the new worker
progress tracker: when adding the new pusher to the list, we also push a \textit{bootstrap message} that informs the new worker about the next
progress-update sequence number it will receive from that direct connection.


\vspace{3mm}
\noindent
When running in cluster mode, each worker process spawns an extra-thread that will accept incoming connections from workers joining the cluster.
Upon accepting the connection, the thread will spawn a pair of \verb|send| and \verb|recv| network threads, perform some bookkeeping and
finally inform the worker threads about the new timely process that is trying to join the cluster.
This is achieved by sending a \verb|RescaleMessage| on a shared \verb|mpsc| channel.

Worker threads need to explicitly check for rescale messages via the \verb|worker::rescale| function call.
This is done in the very beginning of the \verb|worker::step| function.

With the exception of the \textit{bootstrap} protocol that we will talk about in a later section,
this is all from the perspective of worker processes already in the cluster.

\subsection{New Worker Initialization}

Initialization of the new worker boils down to two things:
\begin{itemize}
    \item building the dataflow (possibly more than one)
    \item initialize the progress tracker
\end{itemize}

We will now talk about them in detail.

\subsubsection{Building the dataflow}
Since the binary for the new process is identical to the binary of the other processes,
the construction of the dataflow comes for free.
The single and very important difference is how we handle \textit{capabilities}.
In particular, generic operators such as \verb|source| and \verb|unary_frontier| supply
a capability to the user-provided constructor, which can use it request notifications
or store it to retain the ability of producing output.

Clearly, as the new worker can join at any time in the computation, we must not supply
capabilities for timestamps (epochs) that have been closed already as that would allow
the worker to produce output ``in the past''.

Ideally, one would like to have a capability consistent with the frontier
of that operator at the time of joining the cluster.

% TODO: maybe move to the limitations section

Unfortunately, there are some complications in trying to do this:
\begin{itemize}
    \item As already mentioned, capabilities are passed to the constructor
        of the generic operators while building the dataflow. However, at least
        with the current implementation of the bootstrap protocol, we need to build
        the dataflow \textit{before} actually performing the protocol. But then
        we do not know the operator frontier and thus also the right capability to supply.

    \item If we do supply a capability for a certain timestamp `t`, we need to ensure
        that no other worker will ever consider that timestamp ``closed'' before the new
        worker discard the capability for that timestamp (e.g. by dropping or downgrading it).

\end{itemize}

For the first item, the issue could be worked-around by sending a map to the new
worker which, for each operator, specifies the frontier of that operator.

Then, while building the dataflow, the new worker would look up in the map the frontiers
and supply appropriate capabilities.

An alternative solution, and the one currently implemented, is to \textit{not} supply capabilities at all.
This approach does bring some limitations for the new worker:
\begin{itemize}
    \item Operators can produce output only in response to some input (which comes with the associated capability for that timestamp).
        As such, \verb|source| operators are useless for new worker: they do not hold any capability and cannot produce any output.
    \item Operators cannot request notifications for future times unless they use capabilities that came with input data.
\end{itemize}

There is an asymmetry between workers which hold capabilities (initial workers present in the cluster)
and are capable of injecting new data in the dataflow (via the \verb|source| operators) and workers
that do not hold capabilities as they joined the cluster at a later time. So, while we can add worker
at runtime, there are some special workers.
Looking from a fault-tolerant perspective, where we would like to allow arbitrary worker to crash without
compromising the execution, this could be a showstopper.

\vspace{3mm}
For the second item, the bootstrap worker (see later section about the bootstrapping protocol)
should emit a \verb|(t, +1)|\footnote{it should actually be \verb|num_worker_threads| instead of \verb|+1|, as every new worker thread should get a capability}
pointstamp (progress update), to ensure that the timestamp \verb|t| will not be closed
until the corresponding \verb|(t, -1)| pointstamp is emitted.
Such \verb|(t, -1)| will be emitted by the new worker upon downgrading the capability.

\subsubsection{Initializing the Progress Tracker}
The progress tracking protocol is arguably the most important component at the core of timely computational model.
As such we need to ensure that new workers have an up-to-date and correct view of the progress state.

When building the dataflow, each operator is supplied by default with capabilities for timestamp \verb|0| (or the default analogous for different
timestamp types). Some operators do not require capabilities and simply discard them. Other operators use them to request notification,
produce output, etc.
These operations on capabilities are associated with the emission of progress updates, made of a pair \verb|(pointstamp, delta)|.
These progress updates are broadcasted by every worker to all other workers via the established TCP connections between pair of processes.

There are two alternatives to initialize the progress state of the new worker:
\begin{itemize}
    \item Reconstruct a consistent view by all the frontiers of the operator, which have changed over time as a consequence of progress updates
    \item Record and accumulate every progress update that has been sent so that we can apply them again
\end{itemize}

We implemented the second option, as it is easier to reason about and hard to get wrong. Also,
as progress updates tend to cancel each other out (\verb|+1| and \verb|-1| pairs), we \textit{expect}
such accumulation to remain fairly small, no matter how long the computation has been run for.
We should add proper instrumentation to the code to verify this claim.

In the next two sections we present the two alternatives for implementing the above idea:
\verb|pubsub|-based approach and \verb|peer-to-peer|-based approach, both of them
have been implemented to some extent, but \verb|peer-to-peer| turned out to be a better option.

\subsection{Pub-Sub Approach}

One possible design would be to swap the all-to-all communication pattern for progress updates
with a single \verb|pubsub| system. Such system would have established connection to all workers.
Each worker would send its progress updates that will be broadcasted on its behalf. Each worker
then reads progress updates from every other worker.

Progress updates from each worker could be appended to a queue and when every other worker currently
in the cluster has read the progress updates up to a certain point, updates before that point
can be safely compacted (most term would cancel out).

When a new worker joins the cluster, it would ``subscribe'' to every other worker queue,
initialize its progress tracking state using the compacted updates and finally start reading
new updates from the append-only queue of updates.

A possible implementation of such queue mechanism has been implemented\footnote{https://github.com/LorenzSelv/pubsub}.

\subsubsection{Discussion}

While this sounds like a clean and simple idea, there are a few complications:
\begin{itemize}
    \item To perform updates compaction, the \verb|pubsub| system needs to be aware of timestamp
        data types in the dataflow. Since these timestamps depend on the dataflow that has been constructed,
        the \verb|pubsub| system needs to build the same dataflow, unless we implement some weird export
        mechanism. Moreover, the \verb|pubsub| system needs to use timely data types, which would require
        a circular dependency between the two otherwise-unrelated crates.

    \item More on a philosophical note, adding this external system, which also represents a single point of
        failure, goes a bit against the peer-to-peer spirit of timely.

\end{itemize}

From performances point of view, there would be definitely some overhead associated with the \verb|pubsub|
system itself. Among other things, now there are two hop that a message needs to go through before reaching
its destination. On the other hand, one could easily optimize the amount of progress messages sent around:
you could have a single subscriber per process, so that the same progress messages are not duplicated
because of multiple internal worker threads. This might also solve the communication volume bottleneck
that some experiments show to prevent timely from scaling-out after a certain limit%
\footnote{mostly referring to the results in the Noria paper, but we should perform some proper experiments to investigate this further}.


\subsection{Peer-to-Peer Approach}

An alternative design would be to have the new worker initializes its progress tracking state
by selecting some \textit{bootstrap server} and perform some \textit{bootstrap protocol}.

In particular, the bootstrap server is simply another worker that is selected to help the
new worker initializes its progress tracking state.

The rescale message received by the worker thread contains a flag signaling if the worker thread
was selected as the bootstrap server, and in that case it would initiate the bootstrap protocol.

\subsubsection{Bootstrap Protocol}

Before describing the protocol, we presents some changes needed to make it possible.
To begin with, the server side of the protocol is performed in the \verb|Worker::rescale|\footnote{\verb|timely/src/worker.rs|}
and \verb|TcpAllocator::rescale|\footnote{\verb|communication/src/allocator/zero_copy/allocator.rs|} functions;
the client side of the protocol is performed in the \verb|bootstrap_worker_client|\footnote{\verb|communication/src/rescaling/bootstrap.rs|} function.

Somewhat similarly to the previous approach, each \verb|Progcaster|\footnote{the entity responsible for broadcasting and receiving progress updates
for a specific scope} keeps an accumulation of all progress updates as a \verb|ChangeBatch|.
We define the progress state as this accumulation plus the information about the last sequence number included in the state for each worker.

The bootstrap server, while performing the protocol does not perform other work. Since it needs to use non-thread-safe data
structures, it was not possible to spawn a separate thread to perform the protocol.


The bootstrap protocol (also depicted in Figure \ref{fig:bootstrapprotocol} consists of the following steps:

%% TODO bootstrap protocol pic

We will refer to the new worker joining the cluster as ``bootstrap client''.

\begin{enumerate}
    \item \texttt{Bootstrap client waiting for an incoming connection at some arbitrary bootstrap address}.

    \item \texttt{Bootstrap server initiates the connection to that same address.}

    \item \texttt{Bootstrap server sends the progress tracking state to the new worker and start recording following progress updates.}
        The progress tracking state has been defined above. Recording messages simply means appending them to a list (different for each worker)
        so that we can access them at a later time. The lists are cleared at the end of the protocol.

    \item \texttt{Bootstrap server listens for incoming progress-updates-range requests.}

    \item \texttt{Bootstrap client inspects direct TCP connections with other workers, where it will finds the bootstrap message, containing the next progress-update sequence number it will read from that channel.}
        The bootstrap message is the first message that is sent over the newly-established TCP connection.

    \item \texttt{Bootstrap client computes the missing progress updates ranges by comparing the sequence numbers, in the state and the ones in the bootstrap messages.}
        Since the new worker has the guarantee that it will see all progress updates with sequence number greater or equal to the one in the bootstrap
        message, filling the missing gaps between the received progress state and the such sequence numbers guarantees that it will have seen all
        progress updates.

    \item \texttt{Bootstrap client sends progress-updates-range requests to the bootstrap server.}

    \item \texttt{Bootstrap server sends progress-updates-range responses to the bootstrap client.}
        A progress-updates-range request has the format \texttt{(scope\_id, worker\_index, start/end sequence number)}
        which uniquely identifies some updates range. If the bootstrap server cannot fulfill the request
        as it has not seen all requested messages yet, it will pull more progress updates from the channels with the other workers.
        Eventually, all required progress will be received also by the bootstrap server which
        will be then able to fulfill the request.

    \item \texttt{Bootstrap client terminates the bootstrapping protocol by closing the connection.}

\end{enumerate}


\subsection{Megaphone Integration}

* not much, just number of peers changing over time

\section{Evaluation}

* steady-state overhead compared to timely master (changes slowed down something?)
   - look up diff for any overhead change
   - progress state update

* plot latency vs time (epochs), two lines with expected behaviour:
    1) timely/master can't keep-up with input rate of sentences (linearly increasing)
    2) timely/rescaling can't keep-up as well, and it's slightly higher due to some overhead?
       rescale operation to spawn one/two more workers => spike in latency but the lower

* size of the progress state over time, as a function of:
  - number of workers
  - workload type

* breakdown of timing in the protocol

\section{Limitations and Future Work}

* no removal of workers
* no capabilities at all for new workers
* formal verification of the protocol

\end{document}
